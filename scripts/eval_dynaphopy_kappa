#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Oct 13 12:04:37 2023

@author: sandro_w


This script serves as a wrapper to perform dynaphopy evaluations. 
The primary purpose is to compute the thermal conductivity.
Higher temperature renormalized force constants can optionally be computed.
"""

import argparse
import sys
import dynaphopy.dynamics
import numpy as np
import h5py
import os
import matplotlib.pyplot as plt

import dynaphopy
import mmap
import dynaphopy.dynamics
import dynaphopy.interface.iofile as reading
import dynaphopy.projection as projection

from dynaphopy.power_spectrum import _progress_bar
from dynaphopy.interface.phonopy_link import (
    get_force_sets_from_file,
    get_force_constants_from_file,
    ForceConstants,
)

# from phonopy.harmonic.dynmat_to_fc import DynmatToForceConstants
from dynaphopy.interface.phonopy_link import get_phonon
from dynaphopy.interface.phonopy_link import (
    get_renormalized_force_constants,
    obtain_eigenvectors_and_frequencies,
)
from phonopy.phonon.thermal_properties import mode_cv as get_mode_cv
from phonopy.units import THzToEv
from phonopy.harmonic.dynmat_to_fc import (
    get_commensurate_points,
)  # symmetries are now handled using the GridPoints class
from phonopy.structure.grid_points import GridPoints
from phonopy.file_IO import read_force_constants_hdf5
import phonopy as phpy
from phonopy.units import EV, Angstrom, Kb, THz, VaspToTHz
from phonopy.harmonic.dynmat_to_fc import DynmatToForceConstants
from phonopy.harmonic.force_constants import set_tensor_symmetry_PJ

# this is the only phono3py dependency - unfortunately, the grid points class from phonopy is not quite enough
from phono3py.phonon.grid import (
    BZGrid,
    get_ir_grid_points,
    get_grid_points_by_rotations,
)

import time


def read_ir_grid_points(fname):
    fp = open(fname, "r")
    gpnums = []
    qps = []
    for line in fp:
        elements = line.split()
        if len(elements) > 0:
            if elements[0] == "mesh:":
                mesh = [
                    int(elements[2].split(",")[0]),
                    int(elements[3].split(",")[0]),
                    int(elements[4]),
                ]
        if len(elements) > 1:
            if elements[1] == "grid_point:":
                gpnums.append(int(elements[2]))
            elif elements[0] == "q-point:":
                qps.append(
                    [
                        float(elements[2].split(",")[0]),
                        float(elements[3].split(",")[0]),
                        float(elements[4]),
                    ]
                )
    odict = {}
    odict["gpnums"] = gpnums
    odict["mesh"] = mesh
    odict["qpoints"] = np.array(qps)
    return odict


# I now moved the project functions here - make an independent package out of this with a few files to make it easier to read
def project_onto_wave_vector_lammps_vel(
    fname,
    trajectory,
    q_vector,
    project_on_atom=-1,
    first_vel=1,
    interval=1,
    start_vel=1,
    end_vel=None,
    silent=False,
):
    """
    added by Sandro Wieser
    memory light variant where the velocities are read on the fly instead of relying on a saved trajectory in the memory
    the velocities read are those specific to lammps
    first_vel ... first velocity column index in lammps file
    interval ... interpret only every nth time step
    start_vel ... first velocity to read
    end_vel ... maximum number of time steps to read
    """

    start_time = time.time()
    # Note: trajectory is a Dynamics object
    number_of_primitive_atoms = trajectory.structure.get_number_of_primitive_atoms()
    # if this does not work, need to compute from the supercell
    sqmasses = np.sqrt(np.array(trajectory.structure.get_masses()))
    supercell = (
        trajectory.get_supercell_matrix()
    )  # it is not a matrix, the case of it being one is still considered
    if len(supercell.ravel()) == 3:
        sc_multiplicity = np.prod(supercell)
    else:
        sc_multiplicity = int(round(np.linalg.det(supercell)))

    number_of_atoms = number_of_primitive_atoms * sc_multiplicity
    q_vector_T = []
    velocity_projected = []
    for qv in q_vector:
        q_vector_T.append(qv.T)
        velocity_projected.append([])
    # get_velocity_mass_average multiplies the entire trajectory with the square root of the masses effectively doubling the memory demand
    # this needs to be avoided at all costs
    # velocity = trajectory.get_velocity_mass_average()

    # fetches masses of the primitive uc

    coordinates = trajectory.structure.get_positions(supercell)
    atom_type = np.array(trajectory.structure.get_atom_type_index(supercell=supercell))

    if np.shape(q_vector[0])[0] != coordinates.shape[1]:
        print("ERROR! Q-vector and coordinates dimension do not match")
        exit()

    if (not silent) & (end_vel is not None):
        num_to_read = end_vel - start_vel + 1
        print(
            "Reading %d time steps with %d atoms each..."
            % (num_to_read, number_of_atoms)
        )
        _progress_bar(0, "Reading trajectory")

    first_vel -= 1  # start counting at 0
    # Here, we read the velocities and evaluate them on the fly
    computation_time = 0
    import multiprocessing

    with open(fname) as fp:
        atom_vels = np.zeros((number_of_atoms, 3))
        aid = None
        readmode = False
        tsteps_passed = 0

        with multiprocessing.Pool() as pool:
            for line in fp:
                elements = line.split()
                if len(elements) >= 3:  # individual atoms
                    if (elements[0] != "ITEM:") & readmode:
                        atom_vels[aid] = np.array(
                            list(map(float, elements[first_vel : first_vel + 3]))
                        )
                        aid += 1
                        if aid == number_of_atoms:
                            readmode = False
                            # do the processing
                            if start_vel <= (tsteps_passed + 1):
                                ctime1 = time.time()
                                # Projection into wave vector
                                # parallel version

                                for qid, nv in enumerate(
                                    pool.starmap(
                                        projection.compute_norm_vels,
                                        [
                                            (
                                                qvT,
                                                number_of_primitive_atoms,
                                                project_on_atom,
                                                atom_type,
                                                atom_vels,
                                                coordinates,
                                                sqmasses,
                                            )
                                            for qvT in q_vector_T
                                        ],
                                    )
                                ):
                                    velocity_projected[qid].append(nv)

                                # serial version
                                #                                for qid, qvT in enumerate(q_vector_T):
                                #                                    norm_vels = np.zeros((number_of_primitive_atoms,3),dtype=complex)
                                #                                    for pid in range(number_of_primitive_atoms):
                                #                                        # Projection on atom
                                #                                        if project_on_atom > -1:
                                #                                            if pid != project_on_atom:
                                #                                                continue
                                #                                        atom_list = pid == atom_type
                                #        #                                print(np.shape(mult_qvec),np.shape(coordinates[atom_list,:]),np.shape(atom_vels[atom_list,:]),
                                #        #                                      np.shape(np.dot(coordinates[atom_list,:],q_vector.T)))
                                #                                        norm_vels[pid, :] = np.dot(atom_vels[atom_list,:].T,
                                #                                                                   np.exp(-1j*np.dot(coordinates[atom_list,:],qvT))) * \
                                #                                                                   sqmasses[pid]
                                #
                                #                                    velocity_projected[qid].append(norm_vels)
                                computation_time += time.time() - ctime1

                                if (not silent) & (end_vel is not None):
                                    _progress_bar(
                                        float(tsteps_passed + 1 - start_vel)
                                        / num_to_read,
                                        "Reading trajectory",
                                    )
                            tsteps_passed += 1
                            if end_vel is not None:
                                if tsteps_passed >= end_vel:
                                    break
                    elif (elements[0] == "ITEM:") & (elements[1] == "ATOMS"):
                        readmode = True
                        aid = 0

    #    velocity = trajectory.velocity   # (use the velocity without mass average, just for testing)

    # Normalize velocities (method 1)
    #  for i in range(velocity_projected.shape[1]):
    #      velocity_projected[:,i,:] /= atom_type.count(i)

    # Normalize velocities (method 2)

    velocity_projected = np.array(velocity_projected)
    number_of_primitive_cells = number_of_atoms / number_of_primitive_atoms
    velocity_projected /= np.sqrt(number_of_primitive_cells)
    print(
        "Read and projected trajectory on wave vector in %.2f s with %.2f s computation time"
        % (time.time() - start_time, computation_time)
    )
    return velocity_projected


def project_onto_wave_vector_hdf5(
    fname,
    trajectory,
    q_vector,
    project_on_atom=-1,
    first_vel=1,
    interval=1,
    start_vel=1,
    end_vel=None,
    silent=False,
    out_batch=None,
    qp_obj=None,
    qp_red=None,
):
    """
    added by Sandro Wieser
    memory light variant where the velocities are read on the fly instead of relying on a saved trajectory in the memory
    the velocities are read from an HDF5 file
    first_vel ... first velocity column index in lammps file
    interval ... interpret only every nth time step
    start_vel ... first velocity to read
    end_vel ... maximum number of time steps to read
    out_batch ... how many velocities are stored in memory at once
    qp_obj ... object of the Quasiparticle class, required for consistent batch output
    qp_red ... reduced q points to create proper file names
    """
    import h5py

    start_time = time.time()
    # Note: trajectory is a Dynamics object
    number_of_primitive_atoms = trajectory.structure.get_number_of_primitive_atoms()
    # if this does not work, need to compute from the supercell
    sqmasses = np.sqrt(np.array(trajectory.structure.get_masses()))
    supercell = (
        trajectory.get_supercell_matrix()
    )  # it is not a matrix, the case of it being one is still considered
    if len(supercell.ravel()) == 3:
        sc_multiplicity = np.prod(supercell)
    else:
        sc_multiplicity = int(round(np.linalg.det(supercell)))

    number_of_atoms = number_of_primitive_atoms * sc_multiplicity
    q_vector_T = []
    velocity_projected = []
    for qv in q_vector:
        q_vector_T.append(qv.T)
        if out_batch is None:
            velocity_projected.append([])
        else:
            velocity_projected.append(
                np.zeros((out_batch, number_of_primitive_atoms, 3), dtype=complex)
            )
    # get_velocity_mass_average multiplies the entire trajectory with the square root of the masses effectively doubling the memory demand
    # this needs to be avoided at all costs
    # velocity = trajectory.get_velocity_mass_average()

    # fetches masses of the primitive uc

    coordinates = trajectory.structure.get_positions(supercell)
    atom_type = np.array(trajectory.structure.get_atom_type_index(supercell=supercell))

    if np.shape(q_vector[0])[0] != coordinates.shape[1]:
        print("ERROR! Q-vector and coordinates dimension do not match")
        exit()

    # prepare the output files
    if out_batch is not None:
        file_names = []
        for qid, qp in enumerate(qp_red):
            qpstr = "%f_%f_%f" % (qp[0], qp[1], qp[2])
            file_name = "vc_%s.hdf5" % (qpstr)
            file_names.append(file_name)
            with h5py.File(file_name, "w") as hfp:
                hfp.create_dataset(
                    "vc",
                    (0, number_of_primitive_atoms, 3),
                    dtype="complex",
                    chunks=True,
                    maxshape=(None, number_of_primitive_atoms, 3),
                )
                hfp.create_dataset(
                    "time", (0,), dtype="float", chunks=True, maxshape=(None,)
                )
                hfp.create_dataset(
                    "super_cell", data=qp_obj.dynamic.get_supercell_matrix()
                )
                hfp.create_dataset("reduced_q_vector", data=qp)

        time_values = np.linspace(
            0,
            (out_batch - 1) * qp_obj.dynamic.get_time_step_average(),
            num=out_batch,
        )

    first_vel -= 1  # start counting at 0
    # Here, we read the velocities and evaluate them on the fly
    computation_time = 0
    import multiprocessing

    with h5py.File(fname, "r") as hfp:
        tsteps_passed = 0
        # could pool this better here - but I forgot how this works
        with multiprocessing.Pool() as pool:
            vel_data = hfp["velocities"]
            if end_vel != 0:
                num_to_read = end_vel - start_vel + 1
            else:
                num_to_read = vel_data.shape[0] - start_vel + 1
            if not silent:
                print(
                    "Reading %d time steps with %d atoms each..."
                    % (num_to_read, number_of_atoms)
                )
                _progress_bar(0, "Reading trajectory")
            for vid in range(num_to_read):
                ctime1 = time.time()
                atom_vels = vel_data[vid - start_vel]

                for qid, nv in enumerate(
                    pool.starmap(
                        projection.compute_norm_vels,
                        [
                            (
                                qvT,
                                number_of_primitive_atoms,
                                project_on_atom,
                                atom_type,
                                atom_vels,
                                coordinates,
                                sqmasses,
                            )
                            for qvT in q_vector_T
                        ],
                    )
                ):
                    if out_batch is None:
                        velocity_projected[qid].append(nv)
                    else:
                        velocity_projected[qid][vid % out_batch] = nv
                        if vid % out_batch == out_batch - 1:
                            with h5py.File(file_names[qid], "a") as hfp:
                                hfp["vc"].resize(
                                    (hfp["vc"].shape[0] + out_batch), axis=0
                                )
                                hfp["vc"][-out_batch:] = velocity_projected[qid]
                                hfp["time"].resize(
                                    (hfp["time"].shape[0] + out_batch), axis=0
                                )
                                hfp["time"][-out_batch:] = time_values * (
                                    1 + vid // out_batch
                                )

                    computation_time += time.time() - ctime1

                if not silent:
                    _progress_bar(
                        float(tsteps_passed + 1 - start_vel) / num_to_read,
                        "Reading trajectory",
                    )
                tsteps_passed += 1

    velocity_projected = np.array(velocity_projected)
    number_of_primitive_cells = number_of_atoms / number_of_primitive_atoms
    velocity_projected /= np.sqrt(number_of_primitive_cells)
    print(
        "Read and projected trajectory on wave vector in %.2f s with %.2f s computation time"
        % (time.time() - start_time, computation_time)
    )
    return velocity_projected


# def get_renorm_FCmat_from_dynmats(symmetrize=True):
#
#    phonon = get_phonon(structure, setup_forces=False, custom_supercell=fc_supercell)
#
#    primitive = phonon.get_primitive()
#    supercell = phonon.get_supercell()
#
#    dynmat2fc = DynmatToForceConstants(primitive, supercell)
#
#    size = structure.get_number_of_dimensions() * structure.get_number_of_primitive_atoms()
#    eigenvectors = np.array([eigenvector.reshape(size, size, order='C').T for eigenvector in eigenvectors ])
#    renormalized_frequencies = np.array(renormalized_frequencies)
#
#    try:
#        dynmat2fc.set_dynamical_matrices(renormalized_frequencies / VaspToTHz, eigenvectors)
#
#    except TypeError:
#        frequencies_thz = renormalized_frequencies / VaspToTHz
#        eigenvalues = frequencies_thz ** 2 * np.sign(frequencies_thz)
#        dynmat2fc.create_dynamical_matrices(eigenvalues=eigenvalues,
#                                            eigenvectors=eigenvectors)
#
#    dynmat2fc.run()
#
#    force_constants = ForceConstants(dynmat2fc.get_force_constants(), supercell=fc_supercell)
#
#    # Symmetrize force constants using crystal symmetry
#    if symmetrize:
#        print('Symmetrizing force constants')
#        set_tensor_symmetry_PJ(force_constants.get_array(),
#                               phonon.supercell.get_cell(),
#                               phonon.supercell.get_scaled_positions(),
#                               phonon.symmetry)
#
#    return force_constants


def compute_vc_files(dynobj, qpoints, symmetry=True, hdf5_batch=10000):

    qv_recip = []
    for qp in qpoints:
        qv_recip.append(
            np.dot(
                qp,
                2.0
                * np.pi
                * np.linalg.inv(dynobj.dynamic.structure.get_primitive_cell()).T,
            )
        )
    if "hdf5" in dynobj._traj_file:
        all_vc = projection.project_onto_wave_vector_hdf5(
            dynobj._traj_file,
            dynobj.dynamic,
            np.array(qv_recip),
            project_on_atom=dynobj.parameters.project_on_atom,
            start_vel=dynobj._read_from,
            end_vel=dynobj._read_to,
            silent=dynobj.parameters.silent,
            first_vel=dynobj._first_val,
            out_batch=hdf5_batch,
            qp_obj=dynobj,
            qp_red=qpoints,
        )
    else:
        all_vc = projection.project_onto_wave_vector_lammps_vel(
            dynobj._traj_file,
            dynobj.dynamic,
            np.array(qv_recip),
            project_on_atom=dynobj.parameters.project_on_atom,
            start_vel=dynobj._read_from,
            end_vel=dynobj._read_to,
            silent=dynobj.parameters.silent,
            first_vel=dynobj._first_val,
        )
        dynobj.dynamic.set_time(
            np.linspace(
                0,
                (all_vc[0].shape[0] - 1) * dynobj.dynamic.get_time_step_average(),
                num=all_vc[0].shape[0],
            )
        )

        for vid, vc in enumerate(all_vc):
            qp = qpoints[vid]
            qpstr = "%f_%f_%f" % (qp[0], qp[1], qp[2])
            file_name = "vc_%s.hdf5" % (qpstr)
            reading.save_data_hdf5(
                file_name,
                dynobj.dynamic.get_time(),
                dynobj.dynamic.get_supercell_matrix(),
                vc=vc,
                reduced_q_vector=qp,
            )

        dynobj._vc = all_vc[0]

    print("Projected velocities saved in vc hdf5 files")


def update_h5(hdf5_file, key, data, dtype=None):
    if key not in hdf5_file.keys():
        hdf5_file.create_dataset(key, data=np.array(data), dtype=dtype)
    else:
        stored_quantity = hdf5_file[key]
        stored_quantity[()] = data


def get_cv(temperatures, freqs, cutoff_freq=5000):
    """
    I stole the base version of this from phono3py. credit goes to A. Togo
    Dimension is temperature : number_of_modes
    """
    temperatures = np.array(temperatures)
    cv = np.zeros((len(temperatures), len(freqs)), dtype="double")
    # T/freq has to be large enough to avoid divergence.
    # Otherwise just set 0.
    for i, f in enumerate(freqs):
        finite_t = temperatures > f / 100
        if f > cutoff_freq:
            cv[:, i] = np.where(
                finite_t,
                get_mode_cv(np.where(finite_t, temperatures, 10000), f * THzToEv),
                0,
            )
    return cv


def dyn_partial_clear(dyn):
    # clears everything that is not vc
    dyn._eigenvectors = None
    dyn._frequencies = None
    dyn._vq = None
    dyn._power_spectrum_direct = None
    dyn._power_spectrum_wave_vector = None
    dyn._power_spectrum_phonon = None


def write_2_col(ofname, timevals, data):
    with open(ofname, "w") as fp:
        for t, d in zip(timevals, data):
            fp.write("%12.8f %16.12f\n" % (t, d))


# LAMMPS custom dump file parser
def read_lammps_trajectory(
    file_name,
    structure=None,
    time_step=None,
    limit_number_steps=10000000,
    last_steps=None,
    initial_cut=1,
    end_cut=None,
    memmap=False,
    template=None,
):

    # Time in picoseconds
    # Coordinates in Angstroms

    # Read environtment variables
    try:
        temp_directory = os.environ["DYNAPHOPY_TEMPDIR"]
        if os.path.isdir(temp_directory):
            print("Set temporal directory: {0}".format(temp_directory))
            temp_directory += "/"
        else:
            temp_directory = ""
    except KeyError:
        temp_directory = ""

    number_of_atoms = None
    bounds = None

    # Check file exists
    if not os.path.isfile(file_name):
        print("Trajectory file does not exist!")
        exit()

    # Check time step
    if time_step is None:
        print("Warning! LAMMPS trajectory file does not contain time step information")
        print("Using default: 0.001 ps")
        time_step = 0.001

    # Starting reading
    print("Reading LAMMPS trajectory")
    print("This may take long, please wait..")

    # Dimension of LAMMP calculation
    if structure is None:
        number_of_dimensions = 3
    else:
        number_of_dimensions = structure.get_number_of_dimensions()

    time = []
    data = []
    counter = 0

    lammps_labels = False

    with open(file_name, "r+") as f:

        file_map = mmap.mmap(f.fileno(), 0)

        while True:

            counter += 1

            # Read time steps
            position_number = file_map.find(b"TIMESTEP")
            if position_number < 0:
                break

            file_map.seek(position_number)
            file_map.readline()
            time.append(float(file_map.readline()))

            if number_of_atoms is None:
                # Read number of atoms
                file_map = mmap.mmap(f.fileno(), 0)
                position_number = file_map.find(b"NUMBER OF ATOMS")
                file_map.seek(position_number)
                file_map.readline()
                number_of_atoms = int(file_map.readline())

                # Check if number of atoms is multiple of cell atoms
                if structure is not None:
                    if number_of_atoms % structure.get_number_of_cell_atoms() != 0:
                        print(
                            "Warning: Number of atoms not matching, check LAMMPS output file"
                        )

            if bounds is None:
                # Read cell
                file_map = mmap.mmap(f.fileno(), 0)
                position_number = file_map.find(b"BOX BOUNDS")
                file_map.seek(position_number)
                file_map.readline()

                bounds = []
                for i in range(3):
                    bounds.append(file_map.readline().split())

                bounds = np.array(bounds, dtype=float)
                if bounds.shape[1] == 2:
                    bounds = np.append(bounds, np.array([0, 0, 0])[None].T, axis=1)

                xy = bounds[0, 2]
                xz = bounds[1, 2]
                yz = bounds[2, 2]

                xlo = bounds[0, 0] - np.min([0.0, xy, xz, xy + xz])
                xhi = bounds[0, 1] - np.max([0.0, xy, xz, xy + xz])
                ylo = bounds[1, 0] - np.min([0.0, yz])
                yhi = bounds[1, 1] - np.max([0.0, yz])
                zlo = bounds[2, 0]
                zhi = bounds[2, 1]

                supercell = np.array(
                    [[xhi - xlo, xy, xz], [0, yhi - ylo, yz], [0, 0, zhi - zlo]]
                ).T

                # for 2D
                supercell = supercell[:number_of_dimensions, :number_of_dimensions]

                # Testing cell
                lx = xhi - xlo
                ly = yhi - ylo
                lz = zhi - zlo

                a = lx
                b = np.sqrt(pow(ly, 2) + pow(xy, 2))
                c = np.sqrt(pow(lz, 2) + pow(xz, 2) + pow(yz, 2))

                alpha = np.arccos((xy * xz + ly * yz) / (b * c))
                beta = np.arccos(xz / c)
                gamma = np.arccos(xy / b)

                # End testing cell

                # rotate lammps supercell to match unitcell orientation
                # SW: the original implementation only worked in some cases
                # I think it makes more sense to transform the primitive cell into a lower triangular form and compute the transformation matrix from that

                primcell = structure.get_cell()
                newcell = np.zeros(np.shape(primcell))
                # math is directly taken from the lammps documentation
                normA = np.linalg.norm(primcell[0])
                normB = np.linalg.norm(primcell[1])
                normC = np.linalg.norm(primcell[2])
                newcell[0, 0] = normA
                newcell[1, 0] = np.dot(primcell[1], primcell[0] / normA)
                newcell[1, 1] = np.sqrt(normB**2 - newcell[1, 0] ** 2)
                newcell[2, 0] = np.dot(primcell[2], primcell[0] / normA)
                newcell[2, 1] = (
                    np.dot(primcell[1], primcell[2]) - newcell[1, 0] * newcell[2, 0]
                ) / newcell[1, 1]
                # to prevent negative square root
                sqarg = normC**2 - newcell[2, 0] ** 2 - newcell[2, 1] ** 2
                if abs(sqarg) > 1e-10:
                    newcell[2, 2] = np.sqrt(sqarg)
                else:
                    newcell[2, 2] = 0.0

                transformation_mat_prim = np.matmul(np.linalg.inv(primcell), newcell)
                supercell_matrix = np.matmul(np.linalg.inv(newcell), supercell)
                transformation_mat = np.matmul(
                    transformation_mat_prim, supercell_matrix
                )
                #                print(transformation_mat_prim)
                #                print(transformation_mat)
                #                def unit_matrix(matrix):
                #                    return np.array([np.array(row)/np.linalg.norm(row) for row in matrix])
                #                unit_structure = unit_matrix(structure.get_cell())
                #                unit_supercell_lammps = unit_matrix(supercell)
                #
                #                transformation_mat = np.dot(np.linalg.inv(unit_structure), unit_supercell_lammps).T

                supercell = np.dot(supercell, transformation_mat_prim)

                if memmap:
                    if end_cut:
                        data = np.memmap(
                            temp_directory + "trajectory.{0}".format(os.getpid()),
                            dtype="complex",
                            mode="w+",
                            shape=(
                                end_cut - initial_cut + 1,
                                number_of_atoms,
                                number_of_dimensions,
                            ),
                        )
                    else:
                        print(
                            "Memory mapping requires to define reading range (use read_from/read_to option)"
                        )
                        exit()

            position_number = file_map.find(b"ITEM: ATOMS")

            file_map.seek(position_number)
            lammps_labels = file_map.readline()

            ll = lammps_labels.decode().split()
            if b"vx vy vz" in lammps_labels:
                index_x = ll.index("vx")
                index_y = ll.index("vy")
                index_z = ll.index("vz")
            else:
                index_x = ll.index("x")
                index_y = ll.index("y")
                index_z = ll.index("z")
            # minus 2 because ITEM: ATOMS are not columns
            indices = np.array([index_x, index_y, index_z]) - 2

            # Initial cut control
            if initial_cut > counter:
                time = []
                continue

            # Reading coordinates
            read_coordinates = []
            for i in range(number_of_atoms):
                read_coordinates.append(np.array(file_map.readline().split())[indices])
            read_coordinates = np.array(read_coordinates, dtype=float)

            if template is not None:
                indexing = np.argsort(template)
                read_coordinates = read_coordinates[indexing, :]

            try:
                read_coordinates = np.dot(read_coordinates, transformation_mat_prim)
                if memmap:
                    data[counter - initial_cut, :, :] = read_coordinates  # in angstroms
                else:
                    data.append(read_coordinates)  # in angstroms

            except ValueError:
                print("Error reading step {0}".format(counter))
                break
                # print(read_coordinates)

            # security routine to limit maximum of steps to read and put in memory
            if limit_number_steps + initial_cut < counter:
                print(
                    "Warning! maximum number of steps reached! No more steps will be read"
                )
                break

            if end_cut is not None and end_cut <= counter:
                break

    file_map.close()

    time = np.array(time) * time_step

    if not memmap:
        data = np.array(data, dtype=complex)

        if last_steps is not None:
            data = data[-last_steps:, :, :]
            time = time[-last_steps:]

    # Check position/velocity dump
    if b"vx vy" in lammps_labels:
        return dynaphopy.dynamics.Dynamics(
            structure=structure,
            velocity=data,
            time=time,
            supercell=supercell,
            memmap=memmap,
        )

    if b"x y" in lammps_labels:
        return dynaphopy.dynamics.Dynamics(
            structure=structure,
            trajectory=data,
            time=time,
            supercell=supercell,
            memmap=memmap,
        )

    print("LAMMPS parsing error. Data not recognized: {}".format(lammps_labels))
    exit()


def get_renormalized_force_constants(
    renormalized_frequencies,
    eigenvectors,
    structure,
    fc_supercell,
    symmetrize=True,
    dynobj=None,
    comm_points=None,
):

    if dynobj is None:
        phonon = get_phonon(
            structure, setup_forces=False, custom_supercell=fc_supercell
        )
        primitive = phonon.get_primitive()
        supercell = phonon.get_supercell()

        dynmat2fc = DynmatToForceConstants(primitive, supercell)
    else:
        dynmat2fc = dynobj

    if comm_points is not None:
        dynmat2fc.commensurate_points = comm_points

    size = (
        structure.get_number_of_dimensions() * structure.get_number_of_primitive_atoms()
    )
    eigenvectors = np.array(
        [eigenvector.reshape(size, size, order="C").T for eigenvector in eigenvectors]
    )
    renormalized_frequencies = np.array(renormalized_frequencies)

    try:
        # print(renormalized_frequencies / VaspToTHz)
        # this method takes only 2 arguments, self and dynmat, this can NEVER work
        # dynmat2fc.set_dynamical_matrices(renormalized_frequencies / VaspToTHz, eigenvectors)
        dynmat2fc.create_dynamical_matrices(
            (renormalized_frequencies / VaspToTHz) ** 2
            * np.sign(renormalized_frequencies),
            eigenvectors,
        )

    except TypeError as e:
        print(e)
        frequencies_thz = renormalized_frequencies / VaspToTHz
        eigenvalues = frequencies_thz**2 * np.sign(frequencies_thz)
        dynmat2fc.create_dynamical_matrices(
            eigenvalues=eigenvalues, eigenvectors=eigenvectors
        )

    dynmat2fc.run()

    force_constants = ForceConstants(
        dynmat2fc.get_force_constants(), supercell=fc_supercell
    )

    # Symmetrize force constants using crystal symmetry
    if symmetrize:
        print("Symmetrizing force constants")
        set_tensor_symmetry_PJ(
            force_constants.get_array(),
            phonon.supercell.get_cell(),
            phonon.supercell.get_scaled_positions(),
            phonon.symmetry,
        )

    return force_constants


def eval_dynaphopy_kappa(
    difname,
    trajfname,
    ir_yaml=None,
    read_from=1,
    read_to=None,
    ts=0.001,
    first_val=1,
    ph3py_template=None,
    temperature=300,
    frequency_range=[0, 100],
    renorm_vg=False,
    nosym=False,
    silent=False,
    palgo=2,
    resolution=0.001,
    symprec=1e-5,
    sc_file="SPOSCAR",
    calc_list=[],
    vc_only=False,
    hdf5=None,
):

    warning_list = []
    # set up dynaphopy
    # Get data from input file & process parameters
    #### INPUT PARAMETER FILE PROCESSING START ####
    input_parameters = reading.read_parameters_from_input_file(difname)

    if "structure_file_name_outcar" in input_parameters:
        structure = reading.read_from_file_structure_outcar(
            input_parameters["structure_file_name_outcar"]
        )
        structure_file = input_parameters["structure_file_name_outcar"]
    else:
        structure = reading.read_from_file_structure_poscar(
            input_parameters["structure_file_name_poscar"]
        )
        structure_file = input_parameters["structure_file_name_poscar"]

    structure.get_data_from_dict(input_parameters)

    if "supercell_phonon" in input_parameters:
        supercell_phonon = input_parameters["supercell_phonon"]
    else:
        supercell_phonon = np.identity(3)

    if "force_sets_file_name" in input_parameters:
        structure.set_force_set(
            get_force_sets_from_file(
                file_name=input_parameters["force_sets_file_name"],
                fs_supercell=supercell_phonon,
            )
        )

    if "force_constants_file_name" in input_parameters:
        structure.set_force_constants(
            get_force_constants_from_file(
                file_name=input_parameters["force_constants_file_name"],
                fc_supercell=supercell_phonon,
            )
        )

    if (
        "force_sets_file_name" in input_parameters
        and "force_constants_file_name" in input_parameters
    ):
        assert (
            False
        ), "Both FORCE SETS and FORCE CONSTANTS are found in input file, only one is allowed"

    #### INPUT PARAMETER FILE PROCESSING END ####
    if "hdf5" not in trajfname:
        # read trajectory
        trajectory_reading_function = read_lammps_trajectory

        # Here, we read the first 2 steps to create the trajectory object containing the structure and similar information
        # 2 steps are needed so the time step method in the dynamics object works
        trajectory_2_step = trajectory_reading_function(
            trajfname, structure, ts, initial_cut=0, end_cut=2
        )
    else:
        # for hdf5 files do the same thing - just read like 2 steps from the trajectory and build the dynamics object
        with h5py.File(trajfname, "r") as hfp:
            data = hfp["velocities"][:2]
            if "supercell" in hfp.keys():
                supercell = hfp["supercell"][()]
            else:
                import ase.io

                md_struct = ase.io.read(sc_file)
                supercell = md_struct.cell
        trajectory_2_step = dynaphopy.dynamics.Dynamics(
            structure=structure,
            velocity=data,
            time=np.array(range(len(data))) * ts,
            supercell=supercell,
            memmap=False,
        )
    eigenvectors = []
    all_freqs = []
    # this is necessary to execute so that the dynamics object has the proper time step stored if the velocities were not output every step, might as well print it
    print("time step average:", trajectory_2_step.get_time_step_average())
    ph = get_phonon(trajectory_2_step.structure, symprec=symprec)

    # phono3py version - same results as the phonopy grid points

    bz_grid = BZGrid(
        trajectory_2_step.get_supercell_matrix(),
        lattice=ph.get_primitive().get_cell(),
        symmetry_dataset=ph._primitive_symmetry.dataset,
        is_time_reversal=True,
        use_grg=False,
        store_dense_gp_map=True,
    )

    ir_grid_points, ir_grid_weights, ir_grid_map = get_ir_grid_points(bz_grid)
    # here, the grid points are chosen in a way that they are within the 1. BZ
    actual_bz_gps = np.array(bz_grid.grg2bzg[ir_grid_points], dtype="int_")
    #    print(ir_grid_points)
    #    print(ir_grid_weights)
    #    print(ir_grid_map)

    # TODO: would be nice to have a symmetryless option, where the spectra for symmetry equivalent points are averaged, as dynaphopy could do
    #    if nosym:
    #        pg_ops = None
    #    else:
    pg_ops = ph._primitive_symmetry.get_pointgroup_operations()

    gpobj = GridPoints(
        trajectory_2_step.get_supercell_matrix(),
        np.linalg.inv(ph.get_primitive().get_cell()).T
        * 2
        * np.pi,  # reciprocal cell vectors
        rotations=pg_ops,
    )
    # this has to be done to get all the qpoints in the grid that correspond to the grid addresses
    # required for figuring out equivalent q-points
    shift = np.array(gpobj._is_shift) * 0.5
    all_qpoints = np.array(
        (gpobj.get_grid_address() + shift) / gpobj.mesh_numbers,
        dtype="double",
        order="C",
    )

    # get the actual qpoints in the phono3py definition
    all_bz_qpoints = []
    for qid in range(len(bz_grid.addresses)):
        all_bz_qpoints.append(
            np.dot(bz_grid.Q, bz_grid.addresses[qid] / bz_grid.D_diag.astype("double"))
        )
    #        print(bz_grid.addresses[qid],all_qpoints[qid],bz_grid.get_indices_from_addresses(bz_grid.addresses[qid]),
    #              np.dot(bz_grid.Q, bz_grid.addresses[qid] / bz_grid.D_diag.astype('double')))
    all_bz_qpoints = np.array(all_bz_qpoints)
    scmat = trajectory_2_step.get_supercell_matrix()
    if ir_yaml is not None:
        ir_data = read_ir_grid_points(ir_yaml)
        qpoints = ir_data["qpoints"]
        gpnums = ir_data["gpnums"]
    else:
        if nosym:
            qpoints = all_qpoints
            gpnums = range(len(qpoints))
        else:
            # qpoints = gpobj.get_ir_qpoints()  # careful: the definition of this differs somewhat from phono3py - not exactly the same ir points are computed, however, this script should be able to detect equivalent q points properly

            # gpnums = gpobj.ir_grid_points

            # this is the definition consistent with phono3py
            gpnums = actual_bz_gps
            qpoints = []
            for gpnum in gpnums:
                qpoints.append(all_bz_qpoints[gpnum])
                # print(gpnum,all_bz_qpoints[gpnum])
            qpoints = np.array(qpoints)

    #    print(gpobj.get_ir_grid_points())
    #    print(gpobj.get_ir_grid_weights())
    #    print(gpobj.get_grid_mapping_table())

    if os.path.exists("force_constants_ren.hdf5") or len(calc_list) > 0:
        renormalize_force_constants = False
    else:
        renormalize_force_constants = True
    if os.path.exists("mesh_and_warnings.dat"):
        warning_file = open(
            "mesh_and_warnings.dat", "a"
        )  # append to allow for restarts
    else:
        warning_file = open("mesh_and_warnings.dat", "w")
        warning_file.write(
            "MD cell size relation: [%d %d %d]\n" % (scmat[0], scmat[1], scmat[2])
        )
    print("evaluating %d q-points" % len(qpoints))

    # figure out for which grid points a computation should still be performed
    vc_files = []
    to_compute = []
    for qid, qp in enumerate(qpoints):

        gpnum = gpnums[qid]
        # the bz grid gp_map attribute can convert grid points from the BZ convention to the GridPoints convention
        gp_gpnum = np.where(bz_grid.gp_map == gpnum)[0][0]
        # print(gp_gpnum)
        # print(get_grid_points_by_rotations(gpnum,bz_grid))
        # print(len(gpobj.grid_mapping_table),len(all_qpoints))
        equivalent_qpoints = all_qpoints[gpobj.grid_mapping_table == gp_gpnum]
        # print(equivalent_qpoints)
        qpstr = "%f_%f_%f" % (qp[0], qp[1], qp[2])
        vc_file_name = "vc_%s.hdf5" % (qpstr)
        if os.path.exists(vc_file_name):
            vc_file_exists = True
        else:
            print("%s does not exist, checking equivalent q points..." % vc_file_name)
            vc_file_exists = False
            for equiv_qp in equivalent_qpoints:
                qpstr = "%f_%f_%f" % (
                    equiv_qp[0],
                    equiv_qp[1],
                    equiv_qp[2],
                )  # might be useful to check if equivalent q-points exist
                # check if vc file for this qpoint already exists
                if read_to is not None:
                    vc_file_name = "vc_%s_%d.out" % (qpstr, read_to)
                    if os.path.exists(vc_file_name):
                        vc_file_exists = True
                        break  # too lazy
                    vc_file_name = "vc_%s_%d.hdf5" % (qpstr, read_to)
                    if os.path.exists(vc_file_name):
                        vc_file_exists = True
                        break  # too lazy
                vc_file_name = "vc_%s.hdf5" % (qpstr)
                if os.path.exists(vc_file_name):
                    vc_file_exists = True
                    break  # too lazy

        if vc_file_exists:
            vc_files.append(vc_file_name)
        else:
            qpstr = "%f_%f_%f" % (qp[0], qp[1], qp[2])
            vc_files.append("vc_%s.hdf5" % (qpstr))
            to_compute.append(qp)

    # compute missing q-points
    if len(to_compute) > 0:
        print("evaluating missing vcs for these q-points:")
        print(np.array(to_compute))
        calculation = dynaphopy.Quasiparticle(
            trajectory_2_step,
            last_steps=None,
            traj_file=trajfname,
            hdf5_file=hdf5,
            read_from=read_from,
            read_to=read_to,
            first_val=first_val,
        )
        calculation.parameters.silent = silent
        calculation.set_reduced_q_vector(np.array(qp))
        compute_vc_files(calculation, to_compute)
    if vc_only:
        return
    all_errors = []
    ren_qpoints = []
    for qid, qp in enumerate(qpoints):
        gpnum = gpnums[qid]
        kappafname = "kappa-m%d%d%d-g%d.hdf5" % (scmat[0], scmat[1], scmat[2], gpnum)

        if not os.path.exists(kappafname):
            if (qid not in calc_list) and len(calc_list) > 0:
                print("skipping grid point %d" % gpnum)
                calc_gp = False
            else:
                calc_gp = True
        else:
            calc_gp = False
            print("found %s, skipping grid point %d" % (kappafname, gpnum))
        if calc_gp:

            figdir = "projection_figures_" + str(gpnum)
            if not os.path.exists(figdir):
                os.mkdir(figdir)
            print("grid point:", gpnum)

            print("loading file " + vc_files[qid] + " for q-point " + str(qp) + "...")
            vc_file_name = vc_files[qid]
            vcdata = h5py.File(vc_file_name)
            if args.read_to is not None:
                vcvals = vcdata["vc"][args.read_from - 1 : args.read_to]
                timevals = vcdata["time"][args.read_from - 1 : args.read_to]
            else:
                vcvals = vcdata["vc"][args.read_from - 1 :]
                timevals = vcdata["time"][args.read_from - 1 :]
            trajectory_2_step.set_time(np.array(timevals))
            trajectory = [
                np.array(vcvals),
                np.array(vcdata["reduced_q_vector"]),
                trajectory_2_step,
            ]
            calculation = dynaphopy.Quasiparticle(
                trajectory[2],
                vc=trajectory[0],
                last_steps=None,
                figdir=figdir,
                hdf5_file=hdf5,
            )
            calculation.parameters.silent = silent
            input_parameters.update(
                {"_reduced_q_vector": np.array(qp), "_use_symmetry": False}
            )
            calculation.parameters.get_data_from_dict(input_parameters)
            calculation.set_reduced_q_vector(np.array(qp))
            dyn_partial_clear(calculation)
            calculation.select_power_spectra_algorithm(palgo)

            # write_vc = False
            #            else:
            #
            #                print("computing q-point:", qp)
            #                calculation = dynaphopy.Quasiparticle(trajectory_2_step,
            #                                                  last_steps=None,
            #                                                  traj_file=trajfname,
            #                                                  read_from=read_from,
            #                                                  read_to=read_to,
            #                                                  first_val=first_val,
            #                                                  figdir=figdir)
            #                calculation.set_reduced_q_vector(np.array(qp))
            #                calculation.save_vc_hdf5(vc_file_name)
            # calculation.parameters.get_data_from_dict(input_parameters)
            calculation.set_frequency_limits(frequency_range)
            calculation.set_spectra_resolution(resolution)
            # perform the actual analysis

            phonon_dict = calculation.phonon_individual_analysis()

            # print out the raw spectra
            all_vq = calculation.get_power_spectrum_phonon()
            freqs = calculation.get_frequency_range()
            for mid in range(np.shape(all_vq)[1]):
                ofname = "%s/mode_%03d.spec" % (figdir, mid)
                write_2_col(ofname, freqs, all_vq[:, mid])
            ofname = "%s/mode_sum.spec" % (figdir)
            write_2_col(ofname, freqs, np.sum(all_vq, axis=1))

            all_errors.append(phonon_dict["error"])
            # print(phonon_dict["widths"])
            zero_widths = np.array(phonon_dict["widths"]) == 0
            if np.sum(zero_widths) > 0:
                warning_list.append(
                    "WARNING: Zero Gamma detected in grid point "
                    + str(gpnum)
                    + " for modes with ids "
                    + str(np.array(np.where(np.array(phonon_dict["widths"]) == 0))[0])
                )
                warning_file.write(warning_list[-1] + "\n")

            # ph = get_phonon(calculation.dynamic.structure) # to get the eigenvectors from the phonopy calculation required to compute the renormalized force constants

            # here output the kappa grid point hdf5 file
            """ needs : 
                frequency, 
                gamma, 
                grid_point, 
                group_velocity, 
                gv_by_gv, 
                heat_capacity
                kappa_unit_conversion, - 0.191298
                mesh,
                temperature,
                version - 2.1.0
                
                name:
                kappa-mxxx-gx.hdf5
            """

            filldata = {}
            entries_to_fill = []

            if ph3py_template is not None:
                entries_to_fill = [
                    "grid_point",
                    "group_velocity",
                    "gv_by_gv",
                    "heat_capacity",
                    "kappa_unit_conversion",  # 0.191298
                    "mesh",
                    "temperature",
                    "version",
                ]
                print("using phono3py reference for group velocities")
                templatedata = h5py.File(ph3py_template + "/" + kappafname)
                tempid = np.where(np.array(templatedata["temperature"]) == temperature)
                for entry in entries_to_fill:
                    if (entry == "temperature") | (entry == "heat_capacity"):
                        filldata[entry] = np.array(templatedata[entry][tempid])
                    else:
                        filldata[entry] = np.array(templatedata[entry])
                templatedata.close()

            hdf5_file = h5py.File(kappafname, "w")

            hdf5_file.create_dataset(
                "frequency", data=np.array(phonon_dict["positions"])
            )

            # the widths are 2 Gamma
            hdf5_file.create_dataset(
                "gamma", data=np.array([phonon_dict["widths"]]) / 2
            )

            for entry in entries_to_fill:
                hdf5_file.create_dataset(entry, data=filldata[entry])

            hdf5_file.close()

            # clear all the figures
            for mid in range(structure.get_number_of_primitive_atoms() * 3):
                plt.figure(mid + 1)
                plt.clf()

            frequencies = phonon_dict["positions"]
        elif renormalize_force_constants:
            full_data = h5py.File(kappafname)
            frequencies = full_data["frequency"][()]
            full_data.close()

        # get eigenvectors from phonopy for all equivalent q-points - frequencies are the same
        if renormalize_force_constants:
            gp_gpnum = np.where(bz_grid.gp_map == gpnum)[0][0]
            equivalent_qpoints = all_qpoints[gpobj.grid_mapping_table == gp_gpnum]
            for eqp in equivalent_qpoints:
                arr_evs, freqs = obtain_eigenvectors_and_frequencies(
                    structure, np.array(eqp), print_data=False
                )
                eigenvectors.append(arr_evs)  # Problem will be the symmetries
                all_freqs.append(frequencies)
                ren_qpoints.append(eqp)
                # print(np.mean(frequencies-freqs))

    # get a force constants file
    if renormalize_force_constants:
        print(
            "computing renormalized force constant matrix (inverse eigenvalue problem)"
        )
        renorm_fc = get_renormalized_force_constants(
            np.array(all_freqs),
            np.array(eigenvectors),
            structure,
            scmat,
            symmetrize=False,
            comm_points=ren_qpoints,
        )
        if np.isnan(np.sum(renorm_fc.get_array())):
            warning_list.append("WARNING: nan values in force constant matrix")
        phpy.file_IO.write_force_constants_to_hdf5(
            renorm_fc.get_array(), filename="force_constants_ren.hdf5"
        )
        print("renormalized force constants written to force_constants_ren.hdf5")
    else:
        print("renormalized force constants were already present")
        if renorm_vg:
            print("reading from force_constants_ren.hdf5...")
            renorm_fc = read_force_constants_hdf5("force_constants_ren.hdf5")

    if not ir_yaml:
        # now get the group velocities
        # not done in the main loop as the renormalized FCs might not be known yet
        if renorm_vg:
            trajectory_2_step.structure.set_force_constants(renorm_fc)
            ph = get_phonon(
                trajectory_2_step.structure
            )  # use ph object to compute group velocities

            print("using renormalized force constants...")
        else:
            print("using original harmonic force constants...")

        for qid, qp in enumerate(qpoints):
            print("computing group velocities and heat capacities for " + str(qp))
            gpnum = gpnums[qid]
            kappafname = "kappa-m%d%d%d-g%d.hdf5" % (
                scmat[0],
                scmat[1],
                scmat[2],
                gpnum,
            )
            group_vels = ph.get_group_velocity_at_q(qp)
            gv_by_gv_write = np.zeros(
                (len(group_vels), 6)
            )  # seems to be the phono3py format, not sure yet which element is which
            # phono3py seems to be able to read the 3x3 format
            # but this is the ordering: (xx, yy, zz, yz, xz, xy)
            gv_by_gv = np.zeros((len(group_vels), 3, 3))
            for gid, gv in enumerate(group_vels):
                gv_by_gv[gid] = np.outer(gv, gv)
                gv_by_gv_write[gid] = np.array(
                    [
                        gv_by_gv[gid][0, 0],
                        gv_by_gv[gid][1, 1],
                        gv_by_gv[gid][2, 2],
                        gv_by_gv[gid][1, 2],
                        gv_by_gv[gid][0, 2],
                        gv_by_gv[gid][0, 1],
                    ]
                )

            hdf5_file = h5py.File(kappafname, "r+")

            mode_cv = get_cv([temperature], hdf5_file["frequency"])

            update_h5(hdf5_file, "group_velocity", group_vels)
            update_h5(hdf5_file, "gv_by_gv", gv_by_gv_write)
            update_h5(hdf5_file, "temperature", np.array([temperature]))
            update_h5(hdf5_file, "grid_point", gpnum)
            primcell = ph.get_primitive().cell
            volume = np.abs(np.dot(np.cross(primcell[0], primcell[1]), primcell[2]))
            unit_to_WmK = (THz * Angstrom) ** 2 / (Angstrom**3) * EV / THz / (2 * np.pi)
            update_h5(
                hdf5_file, "kappa_unit_conversion", unit_to_WmK / volume
            )  # not sure about this
            update_h5(hdf5_file, "version", b"2.1.0", dtype="S5")
            update_h5(hdf5_file, "mesh", np.array(scmat))
            update_h5(hdf5_file, "heat_capacity", mode_cv)

            hdf5_file.close()

    qp_evaluated = len(all_errors)
    all_errors = np.array(all_errors).ravel()
    print(
        "mean of all errors reported by dynaphopy: ",
        np.sum(all_errors) / len(all_errors),
    )
    print(
        "sum of all errors reported by dynaphopy divided by the number of q points evaluated: ",
        np.sum(all_errors) / qp_evaluated,
    )
    print("Warnings:")
    for warning in warning_list:
        print(warning)
    warning_file.close()

    return


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="This script serves as a wrapper to perform dynaphopy evaluations. The primary purpose is to compute the thermal conductivity"
    )

    parser.add_argument(
        "--silent",
        dest="silent",
        action="store_true",
        default=False,
        help="silent mode to suppress progress bars and some other output",
    )
    parser.add_argument(
        "--ir_yaml",
        dest="ir_yaml",
        type=str,
        default=None,
        help="file name containing the ir_grid_points from phono3py to compute the thermal conductivity on a mesh. The mesh should be commensurate with the MD supercell. This activates the grid point mode and the script will output individual hdf5 files in the phonopy format ",
    )
    parser.add_argument(
        "--read_from",
        dest="read_from",
        type=int,
        default=1,
        help="first time step to read",
    )
    parser.add_argument(
        "--read_to",
        dest="read_to",
        type=int,
        default=None,
        help="last time step to read",
    )
    parser.add_argument(
        "-temp",
        "--temperature",
        type=float,
        default=300,
        help="temperature of the simulation - needed when reading from phono3py reference - default 300",
    )
    parser.add_argument(
        "-ts", dest="ts", type=float, default=0.001, help="time step in ps"
    )
    parser.add_argument(
        "-fv",
        "--first_val",
        type=int,
        default=1,
        help="index of the first value in the trajectory file",
    )
    parser.add_argument(
        "--ph3py_template",
        dest="ph3py_template",
        type=str,
        default=None,
        help="if this is specified, the other data for the kappa-XXX-gX.hdf5 files is already taken from phono3py files",
    )
    parser.add_argument(
        "--renorm_vg",
        dest="renorm_vg",
        action="store_true",
        default=False,
        help="use renormalized force constants to obtain the group velocities instead of phonopy",
    )

    parser.add_argument(
        "--nosym",
        dest="nosym",
        action="store_true",
        default=False,
        help="do not use symmetries for evaluating the mesh",
    )
    parser.add_argument(
        "--vc_only",
        dest="vc_only",
        action="store_true",
        default=False,
        help="only generate vc files, do not perform the evaluation",
    )
    parser.add_argument(
        "-r",
        "--frequency_range",
        metavar="F",
        type=float,
        nargs=2,
        default=[0, 100],
        help="frequency range of power spectrum in THz (min, max), default:0-100",
    )

    parser.add_argument(
        "--resolution",
        type=float,
        default=0.001,
        help="define power spectrum resolution in THz (default 0.001)",
    )
    parser.add_argument(
        "--palgo",
        dest="palgo",
        type=int,
        default=2,
        help="power spectrum algorithm. 0 = real fourier transform, 1 = maximum entropy, 2 = np.fft, 3 = FFTW, 4 = CUDA FFT; default: 2",
    )
    parser.add_argument(
        "--sc_file",
        dest="sc_file",
        type=str,
        default="SPOSCAR",
        help="structure file required for using the hdf5 read mode when the supercell is not included in the h5 keys. should contain supercell structure in MD.",
    )
    parser.add_argument(
        "--hdf5",
        dest="hdf5",
        type=str,
        default=None,
        help="read phonon information from hdf5 files. needs dataset keys qpoints eigenvectors and frequencies",
    )
    parser.add_argument(
        "--calc_list",
        dest="calc_list",
        type=int,
        nargs="*",
        default=[],
        help="manual list of indices for q-points to evaluate the FTs for. These are NOT the grid points. It is a number from 0 to the total number of q-points to be evaluated minus 1.",
    )

    parser.add_argument("difname", type=str, help="file name of dynaphopy input")
    parser.add_argument(
        "trajfname",
        type=str,
        help="file name of the original trajectory file. If a hdf5 file is specified, the hdf5 reader is used",
    )

    args = parser.parse_args()

    afp = open("p_cmnd.log", "a")
    afp.write(" ".join(sys.argv) + "\n")
    afp.close()

    eval_dynaphopy_kappa(**vars(args))
